# ‚úÖ Checklist T√©cnico SEO

**Fecha:** 29 de enero de 2026  
**P√∫blico:** Developers, DevOps  
**Duraci√≥n:** 10 minutos

---

## üîß Verificaci√≥n Pre-Deploy

### Git y Cambios de C√≥digo

- [ ] Cambios en 404.html (68 l√≠neas nuevas)
  ```bash
  git diff 404.html | head -70
  # Debe mostrar script de redirecci√≥n
  ```

- [ ] Cambios en scripts/postbuild-spa.js (25 l√≠neas nuevas)
  ```bash
  git diff scripts/postbuild-spa.js
  # Debe mostrar: Removed process.exit(0) para SSG
  ```

- [ ] No hay cambios en otros archivos
  ```bash
  git status --short
  # Debe mostrar SOLO: 404.html, postbuild-spa.js
  ```

- [ ] Branch est√° actualizado
  ```bash
  git log --oneline -1
  # Debe mostrar commit reciente
  ```

### Verificaci√≥n de Dependencias

- [ ] Node.js es 18+ (para Vite)
  ```bash
  node --version
  # Esperado: v18.0.0 o superior
  ```

- [ ] npm est√° actualizado
  ```bash
  npm --version
  # Esperado: 8.0.0 o superior
  ```

- [ ] node_modules instalados
  ```bash
  ls node_modules/ | head
  # Debe mostrar carpetas de paquetes
  ```

---

## üèóÔ∏è Verificaci√≥n de Build

### Build SPA (Development)

- [ ] Build client completa sin errores
  ```bash
  npm run build:client
  # Esperado: "Built in X.Xs"
  # Output: ./dist/
  ```

- [ ] 404.html existe en dist
  ```bash
  ls -la dist/404.html
  # Esperado: -rw-r--r-- 1 user user XXXX 404.html
  ```

- [ ] 404.html tiene contenido
  ```bash
  wc -l dist/404.html
  # Esperado: > 30 l√≠neas (no 10)
  ```

- [ ] 404.html contiene script
  ```bash
  grep -q "sessionStorage" dist/404.html && echo "‚úÖ OK" || echo "‚ùå FAIL"
  # Esperado: ‚úÖ OK
  ```

### Build SSG (Production)

- [ ] Build SSG completa sin errores
  ```bash
  npm run build:ssg
  # Esperado: "Built in X.Xs"
  ```

- [ ] Prerender ejecuta correctamente
  ```bash
  npm run prerender
  # Esperado: "‚úÖ Prerendered X pages"
  ```

- [ ] 404.html generado en SSG
  ```bash
  ls -la dist/404.html
  # Debe existir con contenido robusto
  ```

- [ ] Sitemap generado
  ```bash
  ls -la dist/sitemap.xml
  # Debe existir y tener X URLs
  ```

- [ ] index.html contiene script de restauraci√≥n
  ```bash
  grep -A5 "sessionStorage" dist/index.html
  # Debe contener restauraci√≥n de ruta
  ```

---

## üìÇ Verificaci√≥n de Archivos Cr√≠ticos

### 404.html

- [ ] Existe en ra√≠z
  ```bash
  test -f 404.html && echo "‚úÖ OK" || echo "‚ùå MISSING"
  ```

- [ ] Tiene script de redirecci√≥n
  ```bash
  grep -q "window.location = '/index.html'" 404.html && echo "‚úÖ OK" || echo "‚ùå FAIL"
  ```

- [ ] Maneja archivos est√°ticos
  ```bash
  grep -q "isStaticFile\|\.js\|\.css" 404.html && echo "‚úÖ OK" || echo "‚ùå FAIL"
  ```

- [ ] Excepto rutas reales
  ```bash
  grep -q "realFiles\|robots.txt" 404.html && echo "‚úÖ OK" || echo "‚ùå FAIL"
  ```

### index.html

- [ ] Script de restauraci√≥n existe
  ```bash
  grep -A3 "redirectPath" index.html | head -5
  # Debe mostrar la l√≥gica
  ```

- [ ] Se carga despu√©s de contenido
  ```bash
  tail -30 index.html | grep -q "redirectPath" && echo "‚úÖ OK" || echo "‚ùå FAIL"
  ```

### vite.config.ts

- [ ] Base es ra√≠z
  ```bash
  grep "base:" vite.config.ts
  # Esperado: base: '/',
  ```

- [ ] SSR est√° configurado
  ```bash
  grep -q "ssr\|main.ssg" vite.config.ts && echo "‚úÖ OK" || echo "‚ùå FAIL"
  ```

### robots.txt

- [ ] Existe y permite rastreo
  ```bash
  cat robots.txt | head -5
  # Esperado: User-agent: * ‚úÖ
  #           Allow: / ‚úÖ
  ```

- [ ] Contiene sitemap
  ```bash
  grep -q "sitemap.xml" robots.txt && echo "‚úÖ OK" || echo "‚ùå FAIL"
  ```

### CNAME

- [ ] Contiene dominio correcto
  ```bash
  cat CNAME
  # Esperado: fyt-research.org
  ```

---

## üåê Verificaci√≥n de Servidor

### Respuestas HTTP

- [ ] / devuelve 200 OK
  ```bash
  curl -s -o /dev/null -w "%{http_code}" https://fyt-research.org/
  # Esperado: 200
  ```

- [ ] /equipo devuelve 200 OK (despu√©s del fix)
  ```bash
  curl -s -o /dev/null -w "%{http_code}" https://fyt-research.org/equipo
  # Esperado: 200 (antes era 404)
  ```

- [ ] /404.html devuelve 404 (con contenido SPA)
  ```bash
  curl -s -o /dev/null -w "%{http_code}" https://fyt-research.org/404.html
  # Esperado: 404 (correcto, es configurado por GitHub Pages)
  ```

### Headers

- [ ] Cache-Control est√° configurado
  ```bash
  curl -I https://fyt-research.org/index.html | grep Cache-Control
  # Esperado: max-age=XXXX
  ```

- [ ] Content-Type es correcto
  ```bash
  curl -I https://fyt-research.org/ | grep Content-Type
  # Esperado: text/html; charset=utf-8
  ```

- [ ] HTTPS est√° activado
  ```bash
  curl -s -o /dev/null -w "%{http_code}" https://fyt-research.org/
  # Esperado: 200 (no 404, no error SSL)
  ```

---

## üîç Verificaci√≥n SEO

### Sitemap

- [ ] Sitemap existe y es v√°lido
  ```bash
  curl -s https://fyt-research.org/sitemap.xml | head -20
  # Esperado: XML con <url> tags
  ```

- [ ] Sitemap contiene URL correctas
  ```bash
  curl -s https://fyt-research.org/sitemap.xml | grep -c "<url>"
  # Esperado: 35+ URLs
  ```

- [ ] Sitemap est√° en robots.txt
  ```bash
  grep "sitemap" robots.txt
  # Esperado: Sitemap: https://fyt-research.org/sitemap.xml
  ```

### Meta Tags

- [ ] index.html tiene meta tags base
  ```bash
  grep -o 'meta' index.html | wc -l
  # Esperado: 5+ (charset, viewport, etc)
  ```

- [ ] Hay canonical tag
  ```bash
  grep -q 'rel="canonical"' index.html && echo "‚úÖ OK" || echo "‚ùå FAIL"
  ```

### Open Graph

- [ ] og:title existe
  ```bash
  grep -q 'og:title' index.html && echo "‚úÖ OK" || echo "‚ùå FAIL"
  ```

- [ ] og:image existe
  ```bash
  grep -q 'og:image' index.html && echo "‚úÖ OK" || echo "‚ùå FAIL"
  ```

---

## üìä Verificaci√≥n en Google Search Console

### Propiedad

- [ ] Propiedad verificada
  ```
  GSC ‚Üí Settings ‚Üí Users and permissions
  Esperado: Tu cuenta tiene acceso
  ```

- [ ] Dominio correcto
  ```
  Debe ser: fyt-research.org (sin www)
  ```

### Coverage

- [ ] Revisar state actual
  ```
  GSC ‚Üí Coverage
  Tomar nota de:
  - V√°lidas: X
  - Excluidas: Y
  - Errores: Z
  ```

- [ ] No hay 404 errors
  ```
  GSC ‚Üí Coverage ‚Üí Error
  Esperado: 0 (despu√©s del fix)
  ```

### Sitemaps

- [ ] Sitemap est√° registrado
  ```
  GSC ‚Üí Sitemaps
  Esperado: /sitemap.xml (Success)
  ```

- [ ] √öltimas URLs detectadas
  ```
  GSC ‚Üí Sitemaps ‚Üí /sitemap.xml ‚Üí See details
  Debe mostrar las URLs
  ```

---

## üöÄ Pre-Deploy Checklist

Antes de hacer `git push`:

- [ ] Todos los archivos est√°n en git
  ```bash
  git status
  # Esperado: nothing to commit, working tree clean
  ```

- [ ] Los cambios son los esperados
  ```bash
  git diff HEAD
  # Esperado: solo cambios en 404.html y postbuild-spa.js
  ```

- [ ] Branch est√° actualizado
  ```bash
  git pull origin develop
  # Esperado: Already up to date
  ```

- [ ] Rama correcta (develop)
  ```bash
  git branch
  # Esperado: * develop
  ```

---

## üîÑ Post-Deploy Checklist

Despu√©s de `git push`:

### GitHub Actions (30 segundos - 2 minutos)

- [ ] Build inicia autom√°ticamente
  ```
  GitHub ‚Üí Actions ‚Üí Latest workflow
  Esperado: Status "Running"
  ```

- [ ] Build completa exitosamente
  ```
  Esperado: ‚úÖ All checks passed
  Tiempo: 2-3 minutos
  ```

- [ ] Cambios est√°n en main
  ```bash
  git log --oneline | head -2
  # Segundo commit debe ser el nuevo push
  ```

### En Producci√≥n (2 minutos)

- [ ] /404.html es accesible
  ```bash
  curl -I https://fyt-research.org/404.html
  # Esperado: HTTP/2 404
  ```

- [ ] /404.html tiene script
  ```bash
  curl https://fyt-research.org/404.html | grep sessionStorage
  # Esperado: encontrar la l√≠nea de script
  ```

- [ ] P√°gina /equipo funciona
  ```bash
  curl https://fyt-research.org/equipo | grep -q "Team\|Equipo"
  # Esperado: encontrar contenido de p√°gina
  ```

### En Google Search Console (24+ horas)

- [ ] URL Inspection muestra cambios
  ```
  GSC ‚Üí URL Inspection ‚Üí /equipo
  Esperado: ‚úÖ URL is on Google (no 404)
  ```

- [ ] Solicita indexaci√≥n
  ```
  GSC ‚Üí URL Inspection ‚Üí Request indexing
  Repite para todas las 8 URLs con 404
  ```

---

## üéØ Monitoreo Continuo

### Despu√©s de 24 horas

- [ ] Coverage ha mejorado
  ```
  GSC ‚Üí Coverage
  Esperado: Valid pages 22 ‚Üí 25+
  ```

### Despu√©s de 72 horas

- [ ] Coverage est√° en 70%+
  ```
  GSC ‚Üí Coverage
  Esperado: 35+ p√°ginas v√°lidas
  ```

- [ ] No hay errores 404
  ```
  GSC ‚Üí Coverage ‚Üí Error
  Esperado: 0 p√°ginas con 404
  ```

- [ ] Performance muestra actividad
  ```
  GSC ‚Üí Performance
  Esperado: Clicks > 0, Impressions > 100
  ```

---

## üìû Contactos de Soporte

Si algo falla:

1. **GitHub Pages:** Verifica actions logs
2. **Namecheap DNS:** Contacta soporte si SSL no funciona
3. **Google:** GSC ‚Üí Coverage ‚Üí Error para detalles
4. **Dev Team:** Revisa logs locales

---

**√öltima actualizaci√≥n:** 2026-01-29  
**Pr√≥ximo documento:** [SEO_IMPLEMENTATION_SUMMARY.md](SEO_IMPLEMENTATION_SUMMARY.md)
